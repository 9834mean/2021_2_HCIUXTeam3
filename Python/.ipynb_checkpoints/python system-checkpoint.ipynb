{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6196ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtang\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4.element\n",
    "from tqdm.notebook import tqdm\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37371dc7",
   "metadata": {},
   "source": [
    "# Crawling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2bc2c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20211115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da26c70cdfad4863b60cc276c6785dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 분야 크롤링 완료\n",
      "101 분야 크롤링 완료\n",
      "102 분야 크롤링 완료\n",
      "103 분야 크롤링 완료\n",
      "104 분야 크롤링 완료\n",
      "105 분야 크롤링 완료\n"
     ]
    }
   ],
   "source": [
    "date = str(datetime.now())\n",
    "date = date[:date.rfind(':')].replace(' ', '_')\n",
    "date = date.replace(':','시') + '분'\n",
    "today = str(datetime.now().strftime('%Y%m%d'))\n",
    "print(today)\n",
    "\n",
    "def get_soup_obj(url):\n",
    "    headers = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\" }\n",
    "    res = requests.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    \n",
    "    return soup\n",
    "def get_news_contents(url):\n",
    "    soup = get_soup_obj(url)\n",
    "    body = soup.find('div', class_=\"_article_body_contents\")\n",
    "\n",
    "    news_contents = ''\n",
    "    for content in body:\n",
    "        if type(content) is bs4.element.NavigableString and len(content) > 50:\n",
    "            news_contents += content.strip() + ' '\n",
    "\n",
    "    return news_contents\n",
    "\n",
    "def get_news_info(url, s) : \n",
    "    default_img = \"https://search.naver.com/search.naver?where=image&sm=tab_jum&query=naver#\"\n",
    "    current_page = 1     \n",
    "    news_info_list = []\n",
    "\n",
    "    for i in range (10) : \n",
    "        sec_url = url + s + \"&date=\" + today + \"&page=\" + str(current_page)\n",
    "        soup = get_soup_obj(sec_url)\n",
    "        lis = soup.find('ul', class_='type06_headline').find_all(\"li\", limit=15)\n",
    "        \n",
    "        for li in lis : \n",
    "            news_info = {\n",
    "            \"title\" : li.img.attrs.get('alt') if li.img else li.a.text.replace(\"\\n\", \"\").replace(\"\\t\",\"\").replace(\"\\r\",\"\") , \n",
    "            \"date\" : li.find(class_=\"date\").text,\n",
    "            \"news_url\" : li.a.attrs.get('href'),\n",
    "            \"image_url\" :  li.img.attrs.get('src') if li.img else default_img,\n",
    "            \"category\" : s }\n",
    "            try :\n",
    "                news_contents = get_news_contents(news_info['news_url'])\n",
    "                news_info['contetns'] = news_contents\n",
    "                news_info_list.append(news_info)\n",
    "            except Exception as e : \n",
    "                continue\n",
    "        \n",
    "        current_page += 1 \n",
    "    \n",
    "    print(s + \" 분야 크롤링 완료\")    \n",
    "    return news_info_list\n",
    "\n",
    "sid = ['100', '101', '102', '103', '104', '105']\n",
    "default_url = \"https://news.naver.com/main/list.nhn?mode=LSD&mid=sec&sid1=\"\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for s in tqdm(sid) : \n",
    "    news = get_news_info(default_url, s)\n",
    "    df = df.append(news)\n",
    "\n",
    "df.to_csv('네이버뉴스_{}.csv'.format(date), encoding = \"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a52d56",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa81734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
